{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lcmz98gNRU8r"
   },
   "source": [
    "**João Lucas Lage Gonçalves**\n",
    "\n",
    "**23052002**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efPE2CaqRoIb"
   },
   "source": [
    "# Descrição\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzVu99mFRqOw"
   },
   "source": [
    "# Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: socceraction in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from socceraction) (4.9.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from socceraction) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from socceraction) (2.2.2)\n",
      "Requirement already satisfied: pandera<0.18.0,>=0.17.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from socceraction) (0.17.2)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from socceraction) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->socceraction) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->socceraction) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.1.1->socceraction) (2023.3)\n",
      "Requirement already satisfied: multimethod in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (1.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (23.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (1.10.8)\n",
      "Requirement already satisfied: typeguard>=3.0.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (4.3.0)\n",
      "Requirement already satisfied: typing-inspect>=0.6.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandera<0.18.0,>=0.17.2->socceraction) (1.14.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.3.1->socceraction) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.3.1->socceraction) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.3.1->socceraction) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.1->socceraction) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from typeguard>=3.0.2->pandera<0.18.0,>=0.17.2->socceraction) (4.12.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from typing-inspect>=0.6.0->pandera<0.18.0,>=0.17.2->socceraction) (1.0.0)\n",
      "Requirement already satisfied: statsbombpy in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from statsbombpy) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from statsbombpy) (2.31.0)\n",
      "Requirement already satisfied: requests-cache in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from statsbombpy) (1.2.1)\n",
      "Requirement already satisfied: inflect in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from statsbombpy) (7.3.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from statsbombpy) (1.2.0)\n",
      "Requirement already satisfied: more-itertools>=8.5.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from inflect->statsbombpy) (8.12.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from inflect->statsbombpy) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas->statsbombpy) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas->statsbombpy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas->statsbombpy) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from pandas->statsbombpy) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests->statsbombpy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests->statsbombpy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests->statsbombpy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests->statsbombpy) (2024.7.4)\n",
      "Requirement already satisfied: attrs>=21.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests-cache->statsbombpy) (23.2.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests-cache->statsbombpy) (23.2.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests-cache->statsbombpy) (3.10.0)\n",
      "Requirement already satisfied: url-normalize>=1.4 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from requests-cache->statsbombpy) (1.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->statsbombpy) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from typeguard>=4.0.1->inflect->statsbombpy) (4.12.2)\n",
      "Requirement already satisfied: bottleneck in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Collecting bottleneck\n",
      "  Obtaining dependency information for bottleneck from https://files.pythonhosted.org/packages/76/ab/3e95d162d356c853b7c0c084871900d5bdce5e9ad5479396d9641c2dee99/Bottleneck-1.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading Bottleneck-1.4.0-cp311-cp311-win_amd64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jllgo\\anaconda3\\lib\\site-packages (from bottleneck) (1.26.4)\n",
      "Downloading Bottleneck-1.4.0-cp311-cp311-win_amd64.whl (111 kB)\n",
      "   ---------------------------------------- 0.0/111.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/111.6 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 30.7/111.6 kB 435.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 111.6/111.6 kB 921.6 kB/s eta 0:00:00\n",
      "Installing collected packages: bottleneck\n",
      "  Attempting uninstall: bottleneck\n",
      "    Found existing installation: Bottleneck 1.3.5\n",
      "    Uninstalling Bottleneck-1.3.5:\n",
      "      Successfully uninstalled Bottleneck-1.3.5\n",
      "Successfully installed bottleneck-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install socceraction\n",
    "!pip install statsbombpy\n",
    "!pip install --upgrade bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsbombpy import sb\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import brier_score_loss, log_loss, roc_auc_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import socceraction.spadl as spadl\n",
    "from socceraction.data.wyscout import PublicWyscoutLoader\n",
    "from socceraction.vaep import features as ft\n",
    "import socceraction.vaep.labels as lb\n",
    "import socceraction.vaep.formula as vaepformula\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>competition_id</th>\n",
       "      <th>season_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>game_day</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1694440</td>\n",
       "      <td>102</td>\n",
       "      <td>9291</td>\n",
       "      <td>2016-07-10 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9905</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1694439</td>\n",
       "      <td>102</td>\n",
       "      <td>9291</td>\n",
       "      <td>2016-07-07 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3148</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1694438</td>\n",
       "      <td>102</td>\n",
       "      <td>9291</td>\n",
       "      <td>2016-07-06 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9905</td>\n",
       "      <td>10682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1694437</td>\n",
       "      <td>102</td>\n",
       "      <td>9291</td>\n",
       "      <td>2016-07-03 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4418</td>\n",
       "      <td>7839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1694436</td>\n",
       "      <td>102</td>\n",
       "      <td>9291</td>\n",
       "      <td>2016-07-02 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3148</td>\n",
       "      <td>3757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id  competition_id  season_id           game_date  game_day  \\\n",
       "0  1694440             102       9291 2016-07-10 19:00:00         0   \n",
       "1  1694439             102       9291 2016-07-07 19:00:00         0   \n",
       "2  1694438             102       9291 2016-07-06 19:00:00         0   \n",
       "3  1694437             102       9291 2016-07-03 19:00:00         0   \n",
       "4  1694436             102       9291 2016-07-02 19:00:00         0   \n",
       "\n",
       "   home_team_id  away_team_id  \n",
       "0          9905          4418  \n",
       "1          3148          4418  \n",
       "2          9905         10682  \n",
       "3          4418          7839  \n",
       "4          3148          3757  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "WYL = PublicWyscoutLoader(root=DATA_DIR)\n",
    "TRAIN_COMPETITIONS = ['German first division', 'Italian first division', 'French first division', 'Spanish first division', 'English first division']\n",
    "TEST_COMPETITIONS = ['World Cup', 'European Championship']\n",
    "\n",
    "competitions = WYL.competitions()\n",
    "\n",
    "train_competions = competitions[competitions.competition_name.isin(TRAIN_COMPETITIONS)]\n",
    "test_competions = competitions[competitions.competition_name.isin(TEST_COMPETITIONS)]\n",
    "\n",
    "train_games = pd.concat([\n",
    "    WYL.games(competition_id=competition.competition_id, season_id=competition.season_id)\n",
    "    for competition in train_competions.itertuples()\n",
    "])\n",
    "\n",
    "test_games = pd.concat([\n",
    "    WYL.games(competition_id=competition.competition_id, season_id=competition.season_id)\n",
    "    for competition in test_competions.itertuples()\n",
    "])\n",
    "\n",
    "test_games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting training games to SPADL (1826 games):  10%|▉         | 179/1826 [02:38<24:22,  1.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m events \u001b[38;5;241m=\u001b[39m WYL\u001b[38;5;241m.\u001b[39mevents(game\u001b[38;5;241m.\u001b[39mgame_id)\n\u001b[0;32m      6\u001b[0m events \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meventId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubEventId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubtype_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteamId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayerId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatchId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m----> 8\u001b[0m actions_game \u001b[38;5;241m=\u001b[39m spadl\u001b[38;5;241m.\u001b[39mwyscout\u001b[38;5;241m.\u001b[39mconvert_to_actions(events, game\u001b[38;5;241m.\u001b[39mhome_team_id)\n\u001b[0;32m      9\u001b[0m actions_game \u001b[38;5;241m=\u001b[39m spadl\u001b[38;5;241m.\u001b[39mplay_left_to_right(actions\u001b[38;5;241m=\u001b[39mactions_game, home_team_id\u001b[38;5;241m=\u001b[39mgame\u001b[38;5;241m.\u001b[39mhome_team_id)\n\u001b[0;32m     10\u001b[0m actions_game \u001b[38;5;241m=\u001b[39m spadl\u001b[38;5;241m.\u001b[39madd_names(actions_game)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\socceraction\\spadl\\wyscout.py:43\u001b[0m, in \u001b[0;36mconvert_to_actions\u001b[1;34m(events, home_team_id)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mConvert Wyscout events to SPADL actions.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([events, get_tagsdf(events)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m events \u001b[38;5;241m=\u001b[39m make_new_positions(events)\n\u001b[0;32m     44\u001b[0m events \u001b[38;5;241m=\u001b[39m fix_wyscout_events(events)\n\u001b[0;32m     45\u001b[0m actions \u001b[38;5;241m=\u001b[39m create_df_actions(events)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\socceraction\\spadl\\wyscout.py:174\u001b[0m, in \u001b[0;36mmake_new_positions\u001b[1;34m(events)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_new_positions\u001b[39m(events: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract the start and end coordinates for each action.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m        Wyscout event dataframe with start and end coordinates for each action.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     new_positions \u001b[38;5;241m=\u001b[39m events[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositions\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: _make_position_vars(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositions\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m     new_positions\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_y\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    178\u001b[0m     events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(events, new_positions, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\socceraction\\spadl\\wyscout.py:175\u001b[0m, in \u001b[0;36mmake_new_positions.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_new_positions\u001b[39m(events: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract the start and end coordinates for each action.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m        Wyscout event dataframe with start and end coordinates for each action.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     new_positions \u001b[38;5;241m=\u001b[39m events[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositions\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 175\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: _make_position_vars(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositions\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m     new_positions\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_y\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    178\u001b[0m     events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(events, new_positions, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\socceraction\\spadl\\wyscout.py:158\u001b[0m, in \u001b[0;36m_make_position_vars\u001b[1;34m(event_id, positions)\u001b[0m\n\u001b[0;32m    156\u001b[0m     end_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     end_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries([event_id, start_x, start_y, end_x, end_y])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\construction.py:551\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    548\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    550\u001b[0m object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ABCIndex) \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# extract ndarray or ExtensionArray, ensure we have no NumpyExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "games_verbose = list(train_games.itertuples())\n",
    "\n",
    "training_actions = []\n",
    "for game in tqdm(games_verbose, desc=\"Converting training games to SPADL ({} games)\".format(len(games_verbose)), total=len(games_verbose)):\n",
    "    events = WYL.events(game.game_id)\n",
    "    events = events.rename(columns={'id': 'event_id', 'eventId': 'type_id', 'subEventId': 'subtype_id',\n",
    "                            'teamId': 'team_id', 'playerId': 'player_id', 'matchId': 'game_id'})\n",
    "    actions_game = spadl.wyscout.convert_to_actions(events, game.home_team_id)\n",
    "    actions_game = spadl.play_left_to_right(actions=actions_game, home_team_id=game.home_team_id)\n",
    "    actions_game = spadl.add_names(actions_game)\n",
    "    actions_game['home_team_id'] = game.home_team_id\n",
    "    training_actions.append(actions_game)\n",
    "\n",
    "training_df = pd.concat(training_actions).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_verbose = list(test_games.itertuples())\n",
    "\n",
    "test_actions = []\n",
    "for game in tqdm(games_verbose, desc=\"Converting test games to SPADL ({} games)\".format(len(games_verbose)), total=len(games_verbose)):\n",
    "    events = WYL.events(game.game_id)\n",
    "    events = events.rename(columns={'id': 'event_id', 'eventId': 'type_id', 'subEventId': 'subtype_id',\n",
    "                            'teamId': 'team_id', 'playerId': 'player_id', 'matchId': 'game_id'})\n",
    "    actions_game = spadl.wyscout.convert_to_actions(events, game.home_team_id)\n",
    "    actions_game = spadl.play_left_to_right(actions=actions_game, home_team_id=game.home_team_id)\n",
    "    actions_game = spadl.add_names(actions_game)\n",
    "    actions_game['home_team_id'] = game.home_team_id\n",
    "    test_actions.append(actions_game)\n",
    "\n",
    "test_df = pd.concat(test_actions).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_json(DATA_DIR+'\\players.json')\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_json(DATA_DIR+'\\\\teams.json')\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_games['game_date'] = pd.to_datetime(test_games['game_date'])\n",
    "train_games['game_date'] = pd.to_datetime(train_games['game_date'])\n",
    "\n",
    "test_date = test_games['game_date'].min()\n",
    "train_date = train_games['game_date'].min()\n",
    "\n",
    "print(f\"Train date: {train_date}\")\n",
    "print(f\"Test date: {test_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players['player_name'] = players['firstName'] + ' ' + players['lastName']\n",
    "players['player_country'] = players['passportArea'].apply(lambda x: x['name'] if x is not None else None)\n",
    "players['birthDate'] = pd.to_datetime(players['birthDate'])\n",
    "players['train_age'] = (train_date - players['birthDate']).dt.days // 365\n",
    "players['test_age'] = (test_date - players['birthDate']).dt.days // 365\n",
    "\n",
    "players['player_name'] = players['player_name'].str.decode('unicode-escape')\n",
    "players['player_country'] = players['player_country'].str.decode('unicode-escape')\n",
    "players['shortName'] = players['shortName'].str.decode('unicode-escape')\n",
    "players = players.rename(columns={'wyId': 'player_id', 'currentTeamId': 'team_id'})\n",
    "\n",
    "players = players[['player_id', 'player_name', 'shortName', 'player_country', 'train_age', 'test_age', 'team_id']]\n",
    "\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams['team_country'] = teams['area'].apply(lambda x: x['name'] if x is not None else None)\n",
    "teams['name'] = teams['name'].str.decode('unicode-escape')\n",
    "teams['team_country'] = teams['team_country'].str.decode('unicode-escape')\n",
    "\n",
    "teams = teams.rename(columns={'wyId': 'team_id', 'name': 'team_name'})\n",
    "\n",
    "teams = teams[['team_id', 'team_name', 'team_country']]\n",
    "\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatures(actions):\n",
    "    xfns = [\n",
    "        ft.actiontype_onehot,\n",
    "        ft.bodypart_onehot,\n",
    "        ft.result_onehot,\n",
    "        ft.goalscore,\n",
    "        ft.startlocation,\n",
    "        ft.endlocation,\n",
    "        ft.movement,\n",
    "        ft.space_delta,\n",
    "        ft.startpolar,\n",
    "        ft.endpolar,\n",
    "        ft.team,\n",
    "        ft.time,\n",
    "        ft.time_delta\n",
    "    ]\n",
    "\n",
    "    features = []\n",
    "    for game in tqdm(actions.game_id.unique(), desc=\"Creating features\"):\n",
    "        actions_game = actions[actions.game_id==game].reset_index(drop=True)\n",
    "        match_states = ft.gamestates(actions=actions_game)\n",
    "        match_features = pd.concat([fn(match_states) for fn in xfns], axis=1)\n",
    "        features.append(match_features)\n",
    "\n",
    "    features = pd.concat(features).reset_index(drop=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = createFeatures(training_df)\n",
    "test_features = createFeatures(test_df)\n",
    "\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabels(actions):\n",
    "    yfns = [\n",
    "        lb.scores,\n",
    "        lb.concedes\n",
    "    ]\n",
    "\n",
    "    labels = []\n",
    "    for game in tqdm(actions.game_id.unique(), desc=\"Creating labels\"):\n",
    "        actions_game = actions[actions.game_id==game].reset_index(drop=True)\n",
    "        labels.append(pd.concat([fn(actions=actions_game) for fn in yfns], axis=1))\n",
    "\n",
    "    labels = pd.concat(labels).reset_index(drop=True)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = createLabels(actions=training_df)\n",
    "test_labels = createLabels(actions=test_df)\n",
    "\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self, n_estimators, max_depth, n_jobs, verbosity):\n",
    "        self.model = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=n_jobs, verbosity=verbosity)\n",
    "    \n",
    "    def fit(self, X, y):    \n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1].reshape(-1, 1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).reshape(-1, 1)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_proba = self.predict_proba(X)\n",
    "        y_true = y.values\n",
    "        \n",
    "        metrics = {}\n",
    "        metrics = {\n",
    "            \"brier\": brier_score_loss(y_true, y_proba),\n",
    "            \"log_loss\": log_loss(y_true, y_proba),\n",
    "            \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred)\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_esn_estimators = [25,50,100]\n",
    "list_max_depth = [3,5,9]\n",
    "verbosity=1\n",
    "n_jobs=-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimators in list_n_esn_estimators:\n",
    "    for max_depth in list_max_depth:\n",
    "        for label in test_labels.columns:\n",
    "\n",
    "            model_path = f\"./models/xgbc_{label}_est{n_estimators}_dph{max_depth}.pkl\"\n",
    "\n",
    "            if os.path.exists(model_path):\n",
    "                xgbc = XGBoostClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=n_jobs, verbosity=verbosity)\n",
    "                xgbc.model.load_model(model_path)\n",
    "                metrics = xgbc.evaluate(test_features, test_labels[label])\n",
    "            else:\n",
    "                xgbc = XGBoostClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=n_jobs, verbosity=verbosity)\n",
    "                xgbc.fit(training_features, training_labels[label])\n",
    "                metrics = xgbc.evaluate(test_features, test_labels[label])\n",
    "\n",
    "                #xgbc.model.save_model(f\"xgbc_{label}_est{n_estimators}_dph{max_depth}.pkl\")\n",
    "\n",
    "            metrics_list.append({\n",
    "                \"model\": f\"xgbc_{label}_est{n_estimators}_dph{max_depth}\",\n",
    "                \"brier\": metrics[\"brier\"],\n",
    "                \"log_loss\": metrics[\"log_loss\"],\n",
    "                \"roc_auc\": metrics[\"roc_auc\"],\n",
    "                \"accuracy\": metrics[\"accuracy\"]\n",
    "            })       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each metric in a bar chart\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "scores_metrics = metrics_df[metrics_df.model.str.contains('scores')].reset_index(drop=True)\n",
    "concedes_metrics = metrics_df[metrics_df.model.str.contains('concedes')].reset_index(drop=True)\n",
    "\n",
    "scores_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(df, label, metric):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    color = \"blue\" if label==\"scores\" else \"orange\"\n",
    "\n",
    "    sns.barplot(x=\"model\", y=metric, data=df, color=color, label=label)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'Comparison of {metric} between Models')\n",
    "\n",
    "\n",
    "    plt.yscale('log', base=10)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"brier\", \"log_loss\", \"roc_auc\", \"accuracy\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    plot_metrics(scores_metrics, \"scores\", metric)\n",
    "    plot_metrics(concedes_metrics, \"concedes\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"brier\", \"log_loss\", \"roc_auc\", \"accuracy\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    ascending = True if metric==\"brier\" or metric==\"log_loss\" else False\n",
    "    top3 = scores_metrics.sort_values(by=metric).reset_index(drop=True).head(3)\n",
    "    print(f\"Top 3 models for {metric}\")\n",
    "    print(top3['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"brier\", \"log_loss\", \"roc_auc\", \"accuracy\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    ascending = True if metric==\"brier\" or metric==\"log_loss\" else False\n",
    "    top3 = concedes_metrics.sort_values(by=metric).reset_index(drop=True).head(3)\n",
    "    print(f\"Top 3 models for {metric}\")\n",
    "    print(top3['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params =  {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 9,\n",
    "        \"n_jobs\": -3,\n",
    "        \"verbosity\": 1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "features = training_features.columns\n",
    "\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for label in test_labels.columns:\n",
    "        model_path = f\"./models/xgbc_{label}_est{n_estimators}_dph{max_depth}.pkl\"\n",
    "        xgbc = XGBoostClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=n_jobs, verbosity=verbosity)\n",
    "        xgbc.model.load_model(model_path)\n",
    "\n",
    "        models[label] = xgbc\n",
    "\n",
    "        metrics = xgbc.evaluate(test_features, test_labels[label])\n",
    "        print(f\"Metrics for {label}\")\n",
    "        print(metrics)\n",
    "\n",
    "        print(\"##################################################################################\")\n",
    "\n",
    "        features_importance =  xgbc.model.feature_importances_\n",
    "        \n",
    "        feature_importance_df = pd.DataFrame({'label':label, 'feature': features, 'importance': features_importance})\n",
    "        features_df = pd.concat([features_df, feature_importance_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = features_df[features_df['label'] == 'scores']\n",
    "concedes_df = features_df[features_df['label'] == 'concedes']\n",
    "\n",
    "scores_df = scores_df.sort_values(by='importance', ascending=False)\n",
    "concedes_df = concedes_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "def plot_feature_importance(df, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=df)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Importância')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(scores_df.head(10), 'Importância das Features - Scores')\n",
    "plot_feature_importance(concedes_df.head(10), 'Importância das Features - Concedes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo do VAEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateVaep(models, actions):\n",
    "    \n",
    "    predictions = {}\n",
    "    for model in tqdm(['scores', 'concedes'], desc=\"Predicting scores and concedes\"):\n",
    "        predictions[model] = models[model].predict_proba(test_features)[:, 0]\n",
    "    \n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions = vaepformula.value(actions, predictions['scores'], predictions['concedes'])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calculateVaep(models= models, actions=test_df)\n",
    "\n",
    "actions_vaep = pd.concat([test_df, preds], axis=1).reset_index(drop=True)\n",
    "actions_vaep = actions_vaep.sort_values(by=['game_id','period_id','time_seconds'])\n",
    "actions_vaep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_vaep.sort_values(by='vaep_value', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_vaep.sort_values(by='offensive_value', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_vaep.sort_values(by='offensive_value', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_vaep.sort_values(by='defensive_value', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_vaep.sort_values(by='defensive_value', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vaep = actions_vaep[['game_id','type_name','team_id', 'player_id','vaep_value', 'offensive_value', 'defensive_value']]\n",
    "df_vaep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep_players = df_vaep.groupby(['player_id','team_id']).sum().reset_index()\n",
    "\n",
    "vaep_players = vaep_players.merge(players, how='left', on='player_id', suffixes=('', '_player'))\n",
    "vaep_players = vaep_players.drop(columns=['team_id_player'])\n",
    "\n",
    "game_counts = df_vaep.groupby('player_id')['game_id'].nunique().reset_index()\n",
    "game_counts = game_counts.rename(columns={'game_id': 'games_played'})\n",
    "\n",
    "vaep_players = pd.merge(vaep_players, game_counts, on='player_id')\n",
    "\n",
    "vaep_players['vaep_per_game'] = vaep_players['vaep_value'] / vaep_players['games_played']\n",
    "\n",
    "vaep_players = vaep_players.sort_values(by=['vaep_per_game','vaep_value'], ascending=False).reset_index(drop=True)\n",
    "vaep_players[vaep_players['games_played'] > 5].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep_teams = df_vaep.groupby(['team_id']).sum().reset_index()\n",
    "\n",
    "vaep_teams = vaep_teams.merge(teams, how='left', on='team_id', suffixes=('', '_team'))\n",
    "#vaep_teams = vaep_teams.drop(columns=['team_id_team'])\n",
    "\n",
    "game_counts = df_vaep.groupby('team_id')['game_id'].nunique().reset_index()\n",
    "game_counts = game_counts.rename(columns={'game_id': 'games_played'})\n",
    "\n",
    "vaep_teams = pd.merge(vaep_teams, game_counts, on='team_id')\n",
    "\n",
    "vaep_teams['vaep_per_game'] = vaep_teams['vaep_value'] / vaep_teams['games_played']\n",
    "\n",
    "vaep_teams = vaep_teams.sort_values(by=['vaep_per_game','vaep_value'], ascending=False).reset_index(drop=True)\n",
    "vaep_teams[vaep_teams['games_played'] > 5].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaep_actions = df_vaep.groupby(['type_name']).sum().reset_index()\n",
    "\n",
    "action_counts = df_vaep.groupby('type_name').size().reset_index(name='action_count')\n",
    "vaep_actions = pd.merge(vaep_actions, action_counts, on='type_name')\n",
    "\n",
    "vaep_actions['vaep_per_game'] = vaep_actions['vaep_value'] / vaep_actions['action_count']\n",
    "\n",
    "vaep_actions = vaep_actions.sort_values(by=['vaep_per_game','vaep_value'], ascending=False).reset_index(drop=True)\n",
    "vaep_actions[vaep_teams['games_played'] > 5].head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
